{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "x8XYsPA10wOu",
        "outputId": "0ab58649-5623-4621-dc60-0cb8bb431fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1: Broadcasting b over rows of a\n",
            "Array a:\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n",
            "Array b: [10 20 30]\n",
            "\n",
            "Result of a + b:\n",
            " [[11 22 33]\n",
            " [14 25 36]]\n",
            "Explanation: b was broadcast across each row of a.\n",
            "\n",
            "Example 2: Broadcasting d over columns of c\n",
            "Array c:\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n",
            "Array d: [100 200]\n",
            "\n",
            "Result of c + d[:, np.newaxis]:\n",
            " [[101 102 103]\n",
            " [204 205 206]]\n",
            "Explanation: d was broadcast down each column of c.\n",
            "\n",
            "Example 3: Broadcasting scalar f over e\n",
            "Array e:\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n",
            "Scalar f: 100\n",
            "\n",
            "Result of e + f:\n",
            " [[101 102 103]\n",
            " [104 105 106]]\n",
            "Explanation: scalar was broadcast to every element of e.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nBroadcasting doesn't actually copy data ‚Äî it just adjusts how NumPy accesses memory\\nby manipulating the `strides` of the smaller array.\\n\\nIn short:\\n- It lets you write clean code without loops.\\n- It avoids unnecessary memory usage by reusing existing data via views.\\n- It makes vectorized operations more powerful and expressive.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\"\"\"\n",
        "Broadcasting in NumPy allows arrays with different shapes to be used together\n",
        "in arithmetic operations without explicitly reshaping them.\n",
        "\n",
        "Rules for broadcasting:\n",
        "1. Dimensions are aligned from the right.\n",
        "2. Dimensions are compatible if they are equal or one of them is 1.\n",
        "3. New dimensions (with size 1) can be added on the left to match dimension count.\n",
        "\n",
        "If all dimensions are compatible, the arrays can be broadcast together.\n",
        "\"\"\"\n",
        "\n",
        "# ----------------------------\n",
        "# Example 1: Basic Broadcasting\n",
        "# ----------------------------\n",
        "\n",
        "# Create a 2D array (shape: (2, 3))\n",
        "a = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])\n",
        "\n",
        "# Create a 1D array (shape: (3,))\n",
        "b = np.array([10, 20, 30])\n",
        "\n",
        "print(\"Example 1: Broadcasting b over rows of a\")\n",
        "print(\"Array a:\\n\", a)\n",
        "print(\"Array b:\", b)\n",
        "\n",
        "# Add a + b\n",
        "# b is 'virtually' stretched to shape (2, 3):\n",
        "# [[10, 20, 30],\n",
        "#  [10, 20, 30]]\n",
        "result = a + b\n",
        "print(\"\\nResult of a + b:\\n\", result)\n",
        "print(\"Explanation: b was broadcast across each row of a.\")\n",
        "\n",
        "# ----------------------------\n",
        "# Example 2: Broadcasting in Columns\n",
        "# ----------------------------\n",
        "\n",
        "# Create a 2D array (shape: (2, 3))\n",
        "c = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])\n",
        "\n",
        "# Create a 1D array (shape: (2,))\n",
        "d = np.array([100, 200])\n",
        "\n",
        "print(\"\\nExample 2: Broadcasting d over columns of c\")\n",
        "print(\"Array c:\\n\", c)\n",
        "print(\"Array d:\", d)\n",
        "\n",
        "# Add c + d\n",
        "# d has shape (2,), c has shape (2, 3)\n",
        "# d is reshaped to (2, 1), then broadcast to (2, 3):\n",
        "# [[100],\n",
        "#  [200]] -> becomes ->\n",
        "# [[100, 100, 100],\n",
        "#  [200, 200, 200]]\n",
        "result2 = c + d[:, np.newaxis]\n",
        "print(\"\\nResult of c + d[:, np.newaxis]:\\n\", result2)\n",
        "print(\"Explanation: d was broadcast down each column of c.\")\n",
        "\n",
        "# ----------------------------\n",
        "# Example 3: Broadcasting with Scalars\n",
        "# ----------------------------\n",
        "\n",
        "# Create a 2D array (shape: (2, 3))\n",
        "e = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])\n",
        "\n",
        "# Scalar value\n",
        "f = 100\n",
        "\n",
        "print(\"\\nExample 3: Broadcasting scalar f over e\")\n",
        "print(\"Array e:\\n\", e)\n",
        "print(\"Scalar f:\", f)\n",
        "\n",
        "# Add e + f\n",
        "# f is treated as if it had shape (1, 1), and is broadcast to shape (2, 3)\n",
        "result3 = e + f\n",
        "print(\"\\nResult of e + f:\\n\", result3)\n",
        "print(\"Explanation: scalar was broadcast to every element of e.\")\n",
        "\n",
        "# ----------------------------\n",
        "# Summary of What Happened\n",
        "# ----------------------------\n",
        "\n",
        "\"\"\"\n",
        "Broadcasting doesn't actually copy data ‚Äî it just adjusts how NumPy accesses memory\n",
        "by manipulating the `strides` of the smaller array.\n",
        "\n",
        "In short:\n",
        "- It lets you write clean code without loops.\n",
        "- It avoids unnecessary memory usage by reusing existing data via views.\n",
        "- It makes vectorized operations more powerful and expressive.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "size = 1_000_000\n",
        "a = np.random.rand(size)\n",
        "b = np.array([10])\n",
        "\n",
        "# --- With broadcasting ---\n",
        "start = time.time()\n",
        "res1 = a + b\n",
        "broadcast_time = time.time() - start\n",
        "\n",
        "# --- Without broadcasting (manual loop) ---\n",
        "start = time.time()\n",
        "res2 = np.empty_like(a)\n",
        "for i in range(size):\n",
        "    res2[i] = a[i] + b[0]\n",
        "loop_time = time.time() - start\n",
        "\n",
        "print(f\"Broadcast time: {broadcast_time:.5f} sec\")\n",
        "print(f\"Loop time:    {loop_time:.5f} sec\")\n",
        "print(f\"Speedup:      {loop_time / broadcast_time:.2f}x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L1CBolY8gdq",
        "outputId": "6220ff0a-cd7b-4d68-a917-9441b7c2f699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Broadcast time: 0.00315 sec\n",
            "Loop time:    0.54252 sec\n",
            "Speedup:      172.43x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# üî¨ NumPy Internals and Broadcasting Rules  \n",
        "## A Deep Dive into ndarray, dtypes, Memory, and Vectorization\n",
        "\n",
        "This document explores the **core internals of NumPy**, including:\n",
        "- The structure of `ndarray`\n",
        "- Data types (`dtypes`)\n",
        "- Memory layout and management\n",
        "- Vectorization and performance benefits\n",
        "- Broadcasting rules with examples\n",
        "- When to use NumPy (and when not to)\n",
        "\n",
        "---\n",
        "\n",
        "## üì¶ 1. The `ndarray` Object\n",
        "\n",
        "The core of NumPy is the `ndarray` ‚Äî an n-dimensional array object that provides fast access and efficient operations on large datasets.\n",
        "\n",
        "### Key Attributes:\n",
        "| Attribute | Description |\n",
        "|----------|-------------|\n",
        "| `data` | Pointer to raw memory buffer |\n",
        "| `dtype` | Data type of elements |\n",
        "| `shape` | Dimensions (e.g., `(2, 3)`) |\n",
        "| `strides` | Bytes to step in each dimension |\n",
        "| `flags` | Memory layout flags (C/F-contiguous, writeable, etc.) |\n",
        "\n",
        "### Example: Explore `ndarray` attributes\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import ctypes\n",
        "\n",
        "def explore_ndarray_attributes():\n",
        "    arr = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]], dtype=np.int32)\n",
        "    print(\"Array:\\n\", arr)\n",
        "    print(\"\\nData Buffer Address:\", arr.ctypes.data)\n",
        "    print(\"Data Type:\", arr.dtype)\n",
        "    print(\"Shape:\", arr.shape)\n",
        "    print(\"Strides:\", arr.strides)\n",
        "    print(\"Flags:\\n\", arr.flags)\n",
        "\n",
        "    # Slicing creates non-contiguous views\n",
        "    sliced_arr = arr[::2, 1:3]\n",
        "    print(\"\\nSliced Array (Non-contiguous):\\n\", sliced_arr)\n",
        "    print(\"Sliced Array Shape:\", sliced_arr.shape)\n",
        "    print(\"Sliced Array Strides:\", sliced_arr.strides)\n",
        "    print(\"Sliced Array Flags:\\n\", sliced_arr.flags)\n",
        "\n",
        "    # Manual memory access (for illustration only)\n",
        "    offset_bytes = arr.strides[0] * 1 + arr.strides[1] * 1\n",
        "    address_of_element_11 = arr.ctypes.data + offset_bytes\n",
        "    int_pointer = ctypes.cast(address_of_element_11, ctypes.POINTER(ctypes.c_int32))\n",
        "    value_at_address = int_pointer.contents.value\n",
        "    print(f\"\\nAccessing arr[1,1] via strides: {value_at_address}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üíæ 2. NumPy Data Types (`dtypes`)\n",
        "\n",
        "NumPy supports a wide range of data types optimized for performance and size.\n",
        "\n",
        "### Common dtypes and Their Sizes:\n",
        "\n",
        "| Dtype        | Description       | Size (bytes) |\n",
        "|-------------|-------------------|--------------|\n",
        "| `np.int8`   | Signed 8-bit int  | 1            |\n",
        "| `np.int16`  | Signed 16-bit int | 2            |\n",
        "| `np.int32`  | Signed 32-bit int | 4            |\n",
        "| `np.int64`  | Signed 64-bit int | 8            |\n",
        "| `np.float32`| 32-bit float      | 4            |\n",
        "| `np.float64`| 64-bit float      | 8            |\n",
        "| `np.complex64` | Complex number | 8            |\n",
        "| `np.complex128`| Complex number | 16           |\n",
        "| `np.bool_`  | Boolean (True/False) | 1         |\n",
        "| `np.string_`| Fixed-length string | user-defined|\n",
        "\n",
        "### Example: Print dtype info\n",
        "\n",
        "```python\n",
        "def explore_numpy_dtypes():\n",
        "    arr = np.array([1, 2, 3], dtype=np.int32)\n",
        "    print(f\"int32: {arr.dtype}, size: {arr.itemsize} bytes\")\n",
        "```\n",
        "\n",
        "> ‚ö†Ô∏è Choosing the right dtype can save memory and speed up computation.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 3. Memory Layout: C vs. Fortran Contiguous\n",
        "\n",
        "### C-contiguous:\n",
        "- Row-major order\n",
        "- Default in Python\n",
        "- Last index changes fastest\n",
        "\n",
        "### F-contiguous:\n",
        "- Column-major order\n",
        "- Used in languages like MATLAB and Fortran\n",
        "- First index changes fastest\n",
        "\n",
        "### Example:\n",
        "\n",
        "```python\n",
        "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=np.int32)\n",
        "f_arr = np.asfortranarray(arr)\n",
        "print(\"F-contiguous strides:\", f_arr.strides)\n",
        "print(\"Contiguous Check (C):\", f_arr.flags['C_CONTIGUOUS'])\n",
        "print(\"Contiguous Check (F):\", f_arr.flags['F_CONTIGUOUS'])\n",
        "```\n",
        "\n",
        "> ‚úÖ Use `.copy(order='C')` or `.copy(order='F')` if you need a specific layout.\n",
        "\n",
        "---\n",
        "\n",
        "## üß∞ 4. Memory Management in NumPy\n",
        "\n",
        "### Functions:\n",
        "- `np.zeros()` ‚Üí Allocate and initialize to zero\n",
        "- `np.ones()` ‚Üí Allocate and initialize to one\n",
        "- `np.empty()` ‚Üí Allocate without initialization (fastest)\n",
        "- `np.copy()` ‚Üí Create a new copy\n",
        "\n",
        "### Views vs Copies\n",
        "\n",
        "```python\n",
        "a = np.zeros((2, 3))\n",
        "b = a[0, :]   # View\n",
        "c = a.copy()   # Copy\n",
        "\n",
        "b[0] = 99\n",
        "print(\"After modifying view b:\\n\", a)  # a is changed\n",
        "print(\"Copy c remains unchanged:\\n\", c)\n",
        "```\n",
        "\n",
        "> ‚ö†Ô∏è Be careful: Views share memory. Modifying them affects the original.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö° 5. Vectorization: Why It's Fast\n",
        "\n",
        "Vectorized operations are implemented in C, so they're **much faster** than Python loops.\n",
        "\n",
        "### Example: Loop vs Vectorization\n",
        "\n",
        "```python\n",
        "def python_loop_sum(x, y):\n",
        "    result = np.zeros_like(x)\n",
        "    for i in range(len(x)):\n",
        "        result[i] = x[i] + y[i]\n",
        "    return result\n",
        "\n",
        "def numpy_vectorized_sum(x, y):\n",
        "    return x + y\n",
        "\n",
        "size = 1000000\n",
        "a = np.random.rand(size)\n",
        "b = np.random.rand(size)\n",
        "\n",
        "start = time.time()\n",
        "python_loop_sum(a, b)\n",
        "python_time = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "numpy_vectorized_sum(a, b)\n",
        "numpy_time = time.time() - start\n",
        "\n",
        "print(f\"Python loop sum: {python_time:.4f} seconds\")\n",
        "print(f\"NumPy vectorized sum: {numpy_time:.4f} seconds\")\n",
        "print(f\"Speedup: {python_time / numpy_time:.2f}x\")\n",
        "```\n",
        "\n",
        "> üìå Result: ~10‚Äì100x speedups using NumPy!\n",
        "\n",
        "---\n",
        "\n",
        "## üîÅ 6. Broadcasting: Powerful Dimension Matching\n",
        "\n",
        "### Broadcasting Rules:\n",
        "Two dimensions are compatible if:\n",
        "1. They are equal, or\n",
        "2. One of them is 1\n",
        "\n",
        "### Examples:\n",
        "\n",
        "```python\n",
        "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "b = np.array([10, 20, 30])\n",
        "c = np.array([[10], [20]])\n",
        "\n",
        "print(\"a + b:\", a + b)  # shape (2,3) + (3,) ‚Üí broadcasted to (2,3)\n",
        "print(\"a + c:\", a + c)  # shape (2,3) + (2,1) ‚Üí broadcasted to (2,3)\n",
        "```\n",
        "\n",
        "> ‚úÖ Broadcasting avoids copying data and enables elegant, concise code.\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ 7. Challenge: Adjust Image Contrast Using NumPy Broadcasting\n",
        "\n",
        "### Problem:\n",
        "Adjust contrast using:\n",
        "```python\n",
        "output_pixel = (input_pixel - mean) * contrast_factor + mean\n",
        "```\n",
        "\n",
        "### Solution:\n",
        "\n",
        "```python\n",
        "def adjust_contrast_numpy(image, contrast_factor):\n",
        "    mean = np.mean(image)\n",
        "    adjusted_image = (image - mean) * contrast_factor + mean\n",
        "    return np.clip(adjusted_image, 0, 255).astype(np.uint8)\n",
        "\n",
        "def create_sample_image():\n",
        "    return np.array([[100, 150, 200],\n",
        "                     [ 50, 100, 150],\n",
        "                     [ 20,  50, 100]], dtype=np.uint8)\n",
        "```\n",
        "\n",
        "### Test:\n",
        "\n",
        "```python\n",
        "sample_image = create_sample_image()\n",
        "adjusted_image = adjust_contrast_numpy(sample_image, 1.5)\n",
        "print(\"Original:\\n\", sample_image)\n",
        "print(\"Adjusted:\\n\", adjusted_image)\n",
        "```\n",
        "\n",
        "> ‚úÖ This shows how broadcasting simplifies complex image processing.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Summary Table\n",
        "\n",
        "| Feature | List | Generator | Winner |\n",
        "|--------|------|-----------|--------|\n",
        "| Creation Time | ‚ùå Slower | ‚úÖ Very fast | Generator |\n",
        "| Memory Usage | ‚ùå High | ‚úÖ Constant | Generator |\n",
        "| Iteration Speed | ‚úÖ Faster | ‚ùå Slower | List |\n",
        "| Can Be Reused | ‚úÖ Yes | ‚ùå Must recreate | List |\n",
        "| Multiple Iterations | ‚úÖ Yes | ‚ùå No | List |\n",
        "| Random Access | ‚úÖ Yes | ‚ùå No | List |\n",
        "\n",
        "---\n",
        "\n",
        "## üß© When to Use NumPy\n",
        "\n",
        "| Use Case | Recommendation |\n",
        "|----------|----------------|\n",
        "| Large numerical arrays | ‚úÖ Use NumPy |\n",
        "| Vectorized math operations | ‚úÖ Use NumPy |\n",
        "| Interoperability (SciPy, Pandas, Matplotlib) | ‚úÖ Use NumPy |\n",
        "| Small data | ‚ö†Ô∏è Consider plain lists |\n",
        "| Non-numerical data | ‚ö†Ô∏è Use native Python |\n",
        "| GPU acceleration needed | ‚ö†Ô∏è Consider CuPy, PyTorch, TensorFlow |\n",
        "| Sparse data | ‚ö†Ô∏è Consider SciPy.sparse |\n",
        "| Distributed computing | ‚ö†Ô∏è Consider Dask or Spark |\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Final Takeaway\n",
        "\n",
        "| Concept | Insight |\n",
        "|--------|---------|\n",
        "| `ndarray` is memory-efficient | Stores data contiguously |\n",
        "| Strides enable broadcasting | No need to copy data |\n",
        "| Vectorization = C-level speed | Avoid Python loops |\n",
        "| Broadcasting = Elegant syntax | Saves memory and improves readability |\n",
        "| Views = Zero-copy slicing | Use carefully to avoid side effects |\n",
        "| Copies = Independent buffers | Use when you need isolation |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ybdVhpOX0yR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import ctypes\n",
        "\n",
        "def explore_ndarray_attributes():\n",
        "    arr = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]], dtype=np.int32)\n",
        "    print(\"Array:\\n\", arr)\n",
        "    print(\"\\nData Buffer Address:\", arr.ctypes.data)\n",
        "    print(\"Data Type:\", arr.dtype)\n",
        "    print(\"Shape:\", arr.shape)\n",
        "    print(\"Strides:\", arr.strides)\n",
        "    print(\"Flags:\\n\", arr.flags)\n",
        "\n",
        "    # Slicing creates non-contiguous views\n",
        "    sliced_arr = arr[::2, 1:3]\n",
        "    print(\"\\nSliced Array (Non-contiguous):\\n\", sliced_arr)\n",
        "    print(\"Sliced Array Shape:\", sliced_arr.shape)\n",
        "    print(\"Sliced Array Strides:\", sliced_arr.strides)\n",
        "    print(\"Sliced Array Flags:\\n\", sliced_arr.flags)\n",
        "\n",
        "    # Manual memory access (for illustration only)\n",
        "    offset_bytes = arr.strides[0] * 1 + arr.strides[1] * 1\n",
        "    address_of_element_11 = arr.ctypes.data + offset_bytes\n",
        "    int_pointer = ctypes.cast(address_of_element_11, ctypes.POINTER(ctypes.c_int32))\n",
        "    value_at_address = int_pointer.contents.value\n",
        "    print(f\"\\nAccessing arr[1,1] via strides: {value_at_address}\")\n",
        "explore_ndarray_attributes()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x-GQzsp9VB1",
        "outputId": "2c2b1cd8-c62c-4c19-c0ca-7286efaa84ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array:\n",
            " [[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]]\n",
            "\n",
            "Data Buffer Address: 328046736\n",
            "Data Type: int32\n",
            "Shape: (3, 4)\n",
            "Strides: (16, 4)\n",
            "Flags:\n",
            "   C_CONTIGUOUS : True\n",
            "  F_CONTIGUOUS : False\n",
            "  OWNDATA : True\n",
            "  WRITEABLE : True\n",
            "  ALIGNED : True\n",
            "  WRITEBACKIFCOPY : False\n",
            "\n",
            "\n",
            "Sliced Array (Non-contiguous):\n",
            " [[ 2  3]\n",
            " [10 11]]\n",
            "Sliced Array Shape: (2, 2)\n",
            "Sliced Array Strides: (32, 4)\n",
            "Sliced Array Flags:\n",
            "   C_CONTIGUOUS : False\n",
            "  F_CONTIGUOUS : False\n",
            "  OWNDATA : False\n",
            "  WRITEABLE : True\n",
            "  ALIGNED : True\n",
            "  WRITEBACKIFCOPY : False\n",
            "\n",
            "\n",
            "Accessing arr[1,1] via strides: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=np.int32)\n",
        "f_arr = np.asfortranarray(arr)\n",
        "print(\"F-contiguous strides:\", f_arr.strides)\n",
        "print(\"Contiguous Check (C):\", f_arr.flags['C_CONTIGUOUS'])\n",
        "print(\"Contiguous Check (F):\", f_arr.flags['F_CONTIGUOUS'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHxMmIU8-Gut",
        "outputId": "43e6e87c-3c44-4975-ccfb-06716b7f9f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-contiguous strides: (4, 12)\n",
            "Contiguous Check (C): False\n",
            "Contiguous Check (F): True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "````markdown\n",
        "## What are Strides in NumPy?\n",
        "\n",
        "In NumPy, **strides** define how many bytes to step in memory to move to the next element along each axis of an array. It's a low-level detail that allows NumPy to index into memory efficiently without copying data.\n",
        "\n",
        "### Understanding with an Example:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "a = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]], dtype=np.int32)\n",
        "\n",
        "print(\"Array:\\n\", a)\n",
        "print(\"Shape:\", a.shape)\n",
        "print(\"Strides:\", a.strides)\n",
        "````\n",
        "\n",
        "### Output:\n",
        "\n",
        "```\n",
        "Array:\n",
        " [[1 2 3]\n",
        "  [4 5 6]]\n",
        "Shape: (2, 3)\n",
        "Strides: (12, 4)\n",
        "```\n",
        "\n",
        "### Interpretation:\n",
        "\n",
        "* The array has shape `(2, 3)` ‚Äî 2 rows and 3 columns.\n",
        "* Each `int32` element takes **4 bytes**.\n",
        "* The first stride `12` means: to move from one row to the next, NumPy skips **3 integers √ó 4 bytes = 12 bytes**.\n",
        "* The second stride `4` means: to move from one column to the next within the same row, NumPy skips **4 bytes**.\n",
        "\n",
        "### Why It Matters:\n",
        "\n",
        "* Strides make slicing fast without data copying.\n",
        "* You can use `np.lib.stride_tricks.as_strided()` to create sliding window views using custom strides.\n",
        "* They allow advanced memory tricks like viewing the same data in different shapes or steps ‚Äî very powerful for performance tuning.\n",
        "\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "2g9HiMb3-5ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.zeros((2, 3))\n",
        "b = a[0, :]   # View\n",
        "c = a.copy()   # Copy\n",
        "\n",
        "b[0] = 99\n",
        "print(\"After modifying view b:\\n\", a)  # a is changed\n",
        "print(\"Copy c remains unchanged:\\n\", c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY_kR_lOAx5j",
        "outputId": "2fabdfe8-8a70-4515-d335-59712a3e2fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After modifying view b:\n",
            " [[99.  0.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "Copy c remains unchanged:\n",
            " [[0. 0. 0.]\n",
            " [0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def python_loop_sum(x, y):\n",
        "    result = np.zeros_like(x)\n",
        "    for i in range(len(x)):\n",
        "        result[i] = x[i] + y[i]\n",
        "    return result\n",
        "\n",
        "def numpy_vectorized_sum(x, y):\n",
        "    return x + y\n",
        "\n",
        "size = 1000000\n",
        "a = np.random.rand(size)\n",
        "b = np.random.rand(size)\n",
        "\n",
        "start = time.time()\n",
        "python_loop_sum(a, b)\n",
        "python_time = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "numpy_vectorized_sum(a, b)\n",
        "numpy_time = time.time() - start\n",
        "\n",
        "print(f\"Python loop sum: {python_time:.4f} seconds\")\n",
        "print(f\"NumPy vectorized sum: {numpy_time:.4f} seconds\")\n",
        "print(f\"Speedup: {python_time / numpy_time:.2f}x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adIyn844BAF4",
        "outputId": "36f104f1-d3f1-46d4-8444-6e531db52737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python loop sum: 0.3460 seconds\n",
            "NumPy vectorized sum: 0.0025 seconds\n",
            "Speedup: 140.05x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T7xdfhTjBaWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}